---
title: "PRA 2 - Tipología y ciclo de vida de los datos aula 1"
author: "Alejandro Zarza Roa"
date: "2022-05-18"
output: word_document
always_allow_html: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(car)


data_cities <- read.csv("data/datos_agregados_ciudades.csv")
summary(data_cities)


```

# Descripción del dataset

**¿Por qué es importante y qué pregunta/problema pretende responder?**

El dataset elegido para el desarrollo de esta práctica es "Ciudades para
teletrabajar en España", se puede consultar en
<https://www.kaggle.com/datasets/amerono/ciudades-para-teletrabajar-en-espaa>.
Este Dataset contiene información sobre diferentes ciudades de España y
diversas variables relacionadas con su idoneidad para el teletrabajo.
Estas variables resultan útiles para aquellos que se plantean trabajar
de forma remota en España.

Los campos que contiene este dataset son:

-   Nombre del municipio (municipios españoles de más de 75.000
    habitantes)

-   Provincia

-   Comunidad Autónoma

-   Población (fuente de datos: INE, 2022)

-   Kilómetros de carril bici en el municipio por cada 100.000
    habitantes (fuentes de datos: El País, La Sexta, ayuntamientos)

-   Precios de viviendas en alquiler por metro cuadrado (fuente:
    Idealista, marzo 2023)

-   Distancia a Madrid en km (fuente: Google Maps)

-   Tiempo medio de viaje en coche a Madrid (fuente: Google Maps)

-   Tiempo medio de viaje en tren o autobús a Madrid (fuente: Google
    Maps)

-   Distancia a Barcelona en km (fuente: Google Maps)

-   Tiempo medio de viaje en coche a Barcelona (fuente: Google Maps)

-   Tiempo medio de viaje en tren o autobús a Barcelona (fuente: Google
    Maps)

-   Aeropuerto internacional más cercano (fuentes: AENA, Google Maps)

-   Número de conexiones del aeropuerto internacional más cercano
    (fuente: AENA)

-   Distancia en km al aeropuerto internacional más cercano (fuente:
    Google Maps)

-   Temperatura máxima media en ºC (fuente: Weatherspark)

-   Temperatura mínima media en ºC (fuente: Weatherspark)

-   Número de visitantes internacionales (turistas) al año (pendiente de
    completar)

-   Precio medio de venta de viviendas por metro cuadrado (fuente:
    Idealista, marzo 2023)

-   Patrimonio de la Humanidad: Si dispone o no de uno o varios
    Patrimonios (fuente: Wikipedia)

-   Porcentaje de Días con calidad de aire "Buena" (fuente: Ministerio
    para la Transición Ecológica y Reto Demográfico)

-   Porcentaje de Días con calidad de aire "Razonablemente Buena"
    (fuente: Ministerio para la Transición Ecológica y Reto Demográfico)

-   Porcentaje de Días con calidad de aire "Regular" (fuente: Ministerio
    para la Transición Ecológica y Reto Demográfico)

-   Porcentaje de Días con calidad de aire "Desfavorable" (fuente:
    Ministerio para la Transición Ecológica y Reto Demográfico)

-   Porcentaje de Días con calidad de aire "Muy Desfavorable" (fuente:
    Ministerio para la Transición Ecológica y Reto Demográfico)

-   Porcentaje de Días con calidad de aire "Extremadamente Desfavorable"
    (fuente: Ministerio para la Transición Ecológica y Reto Demográfico)

-   Ponderación calidad del aire: Cálculo propio a partir de los 6
    valores anteriores Horas de sol medias anuales (fuente: AEMET)

Recopilando datos sobre aspectos relevantes como la calidad de vida, la
conectividad a internet, el costo de vida, la seguridad, el acceso a
servicios y comodidades, entre otros, el objetivo principal de este
conjunto de datos es identificar las ciudades en España más propicias
para el teletrabajo. Mediante el análisis de esta información, los
teletrabajadores potenciales pueden tomar decisiones informadas sobre
dónde establecerse o realizar viajes de trabajo, teniendo en cuenta
factores clave que impactan en su experiencia de trabajo remoto. En
resumen, este dataset busca proporcionar una guía sólida para aquellos
que desean encontrar entornos ideales para el teletrabajo en España.

El dataset "Ciudades para teletrabajar en España" no solo ofrece
información relevante para la elección de ciudades adecuadas para el
teletrabajo, sino que también desempeña un papel fundamental en la
comprensión de las necesidades y demandas de los teletrabajadores. Esto
permite a las autoridades locales, empresas y profesionales adaptar sus
políticas y servicios para satisfacer estas necesidades de manera
efectiva. Además, el dataset proporciona una base sólida para realizar
análisis exhaustivos del impacto económico y social del teletrabajo en
diferentes regiones de España, lo que contribuye a una toma de
decisiones más informada en torno al fomento y desarrollo del
teletrabajo en el país.

# Integración y selección de los datos de interés a analizar

En este punto, se realiza un descarte de las variables que no sean de interés 

-   Tiempo medio de viaje en coche a Madrid (fuente: Google Maps)

-   Tiempo medio de viaje en tren o autobús a Madrid (fuente: Google
    Maps)
    
-   Tiempo medio de viaje en coche a Barcelona (fuente: Google Maps)

-   Tiempo medio de viaje en tren o autobús a Barcelona (fuente: Google
    Maps)
    
Se descartan estas cuatro ya que son variables que se pueden deducir aproximadamente en función de la distancia en kilómetros, ya que por lo general las comunicaciones son similares.

Debido a la ausencia de valores se descarta también el Número de visitantes internacionales (turistas) al año. Por último, también eliminaremos Patrimonio de la Humanidad, debido a que no resulta de interés.

```{r}
            
# Especifica las columnas que deseas eliminar
columnas_a_borrar <- c("Tiempo.medio..de.viaje.a.Madrid..en.coche", "Tiempo.medio.de.viaje.a.Madrid.en.tren.o.autobús", "Tiempo.medio..de.viaje.a.Barcelona..en.coche", "Tiempo.medio.de.viaje.a.Barcelona.en.tren.o.autobús", "Número.de.visitantes.internacionales.al.año", "Patrimonio.de.la.Humanidad")

data_cities <- data_cities[, -which(names(data_cities) %in% columnas_a_borrar)]
#data_cities <- subset(data_cities, select = -columnas_a_borrar)
summary(data_cities)

```

# Limpieza de los datos

 Gestión de ceros o elementos vacíos
 
```{r}
# Verificar si hay valores nulos por columna en el dataset
nulos <- colSums(data_cities == "N/D", na.rm = TRUE)

# Imprimir los resultados
print(nulos)

```


Las columnas que tienen valores N/D son Carril.Bici, Precios.alquiler, Precio.medio.vivienda..EUR.m2.,  X..días.calidad.del.aire.Buena, X..días.calidad.del.aire.Razonablemente.Buena, X..días.calidad.del.aire.Regular,X..días.calidad.del.aire.Desfavorable,X..días.calidad.del.aire.Muy.Desfavorable,X..días.calidad.del.aire.Extremadamente.Desfavorable,Ponderación.calidad.del.aire, Horas.de.Sol.medias.anuales.

Como hemos visto al inicio, muchos de los valores que deberían ser numéricos están puestos de tipo character. Por lo tanto, antes de gestionar los valores extremos vamos a transformar dichas variables.

```{r}     
          
data_cities$Carril.Bici <- as.numeric(data_cities$Carril.Bici)
data_cities$Precios.alquiler <- as.numeric(data_cities$Precios.alquiler)
data_cities$Distancia.al.aeropuerto.internacional.más.cercano..km <- as.numeric(data_cities$Distancia.al.aeropuerto.internacional.más.cercano..km)
data_cities$Temperatura.mínima.media..ºC. <- as.numeric(data_cities$Temperatura.mínima.media..ºC.)
data_cities$Precio.medio.vivienda..EUR.m2. <- as.numeric(data_cities$Precio.medio.vivienda..EUR.m2.)
data_cities$X..días.calidad.del.aire.Buena <- as.numeric(data_cities$X..días.calidad.del.aire.Buena)
data_cities$Distancia.al.aeropuerto.internacional.más.cercano..km. <- as.numeric(data_cities$Distancia.al.aeropuerto.internacional.más.cercano..km.)
data_cities$X..días.calidad.del.aire.Razonablemente.Buena <- as.numeric(data_cities$X..días.calidad.del.aire.Razonablemente.Buena)
data_cities$X..días.calidad.del.aire.Regular <- as.numeric(data_cities$X..días.calidad.del.aire.Regular)
data_cities$X..días.calidad.del.aire.Desfavorable <- as.numeric(data_cities$X..días.calidad.del.aire.Desfavorable)
data_cities$X..días.calidad.del.aire.Muy.Desfavorable <- as.numeric(data_cities$X..días.calidad.del.aire.Muy.Desfavorable)
data_cities$X..días.calidad.del.aire.Extremadamente.Desfavorable <- as.numeric(data_cities$X..días.calidad.del.aire.Extremadamente.Desfavorable)
data_cities$Ponderación.calidad.del.aire <- as.numeric(data_cities$Ponderación.calidad.del.aire)
data_cities$Horas.de.Sol.medias.anuales <- as.numeric(gsub("\\.", "", data_cities$Horas.de.Sol.medias.anuales))
print(data_cities$Horas.de.Sol.medias.anuales)
#data_cities$Horas.de.Sol.medias.anuales <- as.numeric(data_cities$Horas.de.Sol.medias.anuales)


summary(data_cities)

```

Debido a la importancia que le voy a dar en este estudio, voy a descartar las ciudades de las que no tenemos métricas acerca de la calidad del aire.

```{r}

# Eliminar filas con valor "N/D" en la columna "Ponderación.calidad.del.aire"
data_cities <- subset(data_cities, !Ponderación.calidad.del.aire %in% "N/D")

# Verificar si hay valores nulos por columna en el dataset
nulos <- colSums(data_cities == "N/D", na.rm = TRUE)

# Imprimir los resultados
print(nulos)

```

Cambio las ciudades que no tienen datos de los kilómetros de carril bici por cero.

```{r}

data_cities$Carril.Bici <- ifelse(data_cities$Carril.Bici == "N/D", 0, data_cities$Carril.Bici)

```

Ahora únicamente quedaria gestionar los valores de los precios de la vivienda, del alquiler y las horas de sol medias anuales. Para ello, voy a hacer una media entre los valores de la misma Provincia.

```{r}

# Reemplazar los valores "N/D" por el precio medio por Provincia
data_cities$Precios.alquiler <- with(data_cities, ifelse(Precios.alquiler == "N/D",
                                                ave(as.numeric(Precios.alquiler),
                                                    Provincia,
                                                    FUN = function(x) mean(x, na.rm = TRUE)),
                                                Precios.alquiler))

data_cities$Precio.medio.vivienda..EUR.m2. <- as.numeric(gsub("\\.", "", data_cities$Precio.medio.vivienda..EUR.m2.))

data_cities$Precio.medio.vivienda..EUR.m2. <- with(data_cities, ifelse(Precio.medio.vivienda..EUR.m2. == "N/D",
                                              ave(as.numeric(Precio.medio.vivienda..EUR.m2.),
                                                  Provincia,
                                                  FUN = function(x) mean(x, na.rm = TRUE)),
                                              ifelse(as.numeric(Precio.medio.vivienda..EUR.m2.) < 100,
                                            ave(as.numeric(Precio.medio.vivienda..EUR.m2.),
                                              Provincia,
                                              FUN = function(x) mean(x[x > 100], na.rm = TRUE)),
                                              Precio.medio.vivienda..EUR.m2.)))



data_cities$Horas.de.Sol.medias.anuales <- with(data_cities, ifelse(Horas.de.Sol.medias.anuales == "N/D",
                                            ave(as.numeric(Horas.de.Sol.medias.anuales),
                                              Provincia,
                                              FUN = function(x) mean(x[x > 100], na.rm=TRUE)),
                                            ifelse(as.numeric(Horas.de.Sol.medias.anuales) < 100,
                                            ave(as.numeric(Horas.de.Sol.medias.anuales),
                                              Provincia,
                                              FUN = function(x) mean(x[x > 100], na.rm = TRUE)),
                                              Horas.de.Sol.medias.anuales)))

print(data_cities$Precio.medio.vivienda..EUR.m2.)

data_clean <- data_cities[complete.cases(data_cities), ]
print(data_clean$Horas.de.Sol.medias.anuales)
# Verificar si hay valores nulos por columna en el dataset
nulos <- colSums(data_cities == "N/D", na.rm = TRUE)

# Imprimir los resultados
print(nulos)

```

# Gestión de valores extremos



```{r}

# Obtener las variables numéricas del dataset
variables_numericas <- sapply(data_cities, is.numeric)

# Mostrar las variables numéricas
nombres_variables_numericas <- names(variables_numericas[variables_numericas])
print(nombres_variables_numericas)


# Crear boxplots para cada variable numérica
for (i in 1:length(nombres_variables_numericas)) {
  variable <- nombres_variables_numericas[i]
  boxplot(data_cities[,variable], main = variable, ylab = "")
}



```

Se observan algunos valores que se encuentran bastante fuera de los diagramas. Sin embargo esto se debe a diversos factores como la diferencia de habitantes en una población como Barcelona o Madrid con los municipios más pequeños, ya que se han considerado ciudades con un valor mínimo de 75000 habitantes.

Por otro lado también tenemos diferencias muy sifnificativas en las distancias a Barcelona y a Madrid ya que también se uncluyen poblaciones en Islas Canarias o Ceuta.



# Análisis de los datos.
4.1. Selección de los grupos de datos que se quieren analizar/comparar (p.
ej., si se van a comparar grupos de datos, ¿cuáles son estos grupos y
qué tipo de análisis se van a aplicar?)


Las variables que se van a utilizar para este apartado de análisis son: 

- Ponderación calidad del aire: Es importante considerarla, ya que la calidad del aire tiene un gran impacto en la salud y el bienestar de los trabajadores remotos.

- Precios alquiler: Esta variable es importante para analizar el costo de vida en cada ciudad.

- Precio medio vivienda (EUR/m2): Al igual que los precios de alquiler, el precio medio de la vivienda puede proporcionar información valiosa sobre el costo de vida en cada ciudad.

- Distancia al aeropuerto internacional más cercano (km): Un alto porcentaje de trabajadores remotos o bien son extranjeros, o precisan viajar de vez en cuando a la oficina.

- Carril Bici: Esta variable puede indicar la disponibilidad de infraestructura para el ciclismo y promover un medio de transporte saludable y respetuoso con el medio ambiente.

- Horas de Sol medias: Estas horas de sol pueden tener un impacto en el estado de ánimo y la productividad de los trabajadores remotos.



```{r}

variables <- c("Ponderación.calidad.del.aire", "Precios.alquiler", "Precio.medio.vivienda..EUR.m2.",
               "Distancia.al.aeropuerto.internacional.más.cercano..km.", "Carril.Bici", "Horas.de.Sol.medias.anuales")
data_analisis <- data_cities[, variables]

summary(data_analisis)

```


4.2. Comprobación de la normalidad y homogeneidad de la varianza.


```{r}

data_analisis <- na.omit(data_analisis)
print(data_analisis$Precios.alquiler)
for (variable in data_analisis) {

  shapiro.test(variable)
  
}

# Convertir variables a numérico para tratar de corregir 
data_analisis$Ponderación.calidad.del.aire <- as.numeric(data_analisis$Ponderación.calidad.del.aire)
data_analisis$Precios.alquiler <- as.numeric(data_analisis$Precios.alquiler)
data_analisis$Precio.medio.vivienda..EUR.m2. <- as.numeric(data_analisis$Precio.medio.vivienda..EUR.m2.)
data_analisis$Distancia.al.aeropuerto.internacional.más.cercano..km. <- as.numeric(data_analisis$Distancia.al.aeropuerto.internacional.más.cercano..km.)
data_analisis$Carril.Bici <- as.numeric(data_analisis$Carril.Bici)
data_analisis$Horas.de.Sol.medias <- as.numeric(data_analisis$Horas.de.Sol.medias)


# Prueba de homogeneidad de varianza


leveneTest(data_analisis)


```



4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos.
En función de los datos y el objetivo del estudio, aplicar pruebas de
contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos
tres métodos de análisis diferentes.


```{r}

data_analisis$Carril.Bici <- as.numeric(data_analisis$Carril.Bici)
data_analisis$Precios.alquiler <- as.numeric(data_analisis$Precios.alquiler)

# Prueba de contraste de hipótesis (t-test)
t.test(data_analisis$Precios.alquiler ~ data_analisis$Carril.Bici)

# Correlación de variables (coeficiente de correlación de Pearson)
cor(data_analisis$Ponderación.calidad.del.aire, data_analisis$Precio.medio.vivienda..EUR.m2., method = "pearson")

# Regresión lineal
modelo_regresion <- lm(Precios.alquiler ~ Distancia.al.aeropuerto.internacional.más.cercano..km. + Carril.Bici + Horas.de.Sol.medias, data = data_analisis)
summary(modelo_regresion)


```


# Resolución del problema

Debido a problemas con la presencia de valores NA en un dataset no puedo llegar a una conclusión final con estos datos. Por lo tanto voy a plantear diferentes puntos de vista y análisis que tenía en mente.

Lo he querido apoyar en tres factores fundamentales a la hora de elegir vivir en una ciudad determinada:

- Evaluación de la calidad del aire: Si la variable "Ponderación calidad del aire" muestra diferencias significativas entre las ciudades, se pueden identificar las ciudades con la mejor y peor calidad del aire para tomar decisiones relacionadas con la ubicación del teletrabajo.

- Análisis de precios: Comparando las variables "Precios alquiler" y "Precio medio vivienda (EUR/m2)", se puede determinar si hay una correlación entre los precios de alquiler y los precios de venta de viviendas en las ciudades. Esto puede ayudar a tomar decisiones sobre el tipo de vivienda a considerar en cada ciudad.

- Accesibilidad y transporte: Evaluando la variable "Distancia al aeropuerto internacional más cercano (km)" y el dato de "Carril Bici", se puede analizar la disponibilidad y facilidad de transporte en las ciudades. Esto puede ser relevante para aquellos que requieren viajar con frecuencia o desean utilizar la bicicleta como medio de transporte.



